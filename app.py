import streamlit as st
import pandas as pd
import google.generativeai as genai
from datetime import datetime
import io

# --- CONFIGURATION ---
st.set_page_config(page_title="Assistant AGOrA", page_icon="üéì")
st.title("üéì Assistant PFMP AGOrA")

# R√©cup√©ration s√©curis√©e de la cl√© API
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("La cl√© API est manquante. Configurez les 'Secrets' dans Streamlit.")
    st.stop()

# --- LE PROMPT AGORA (Votre "Gem") ---
SYSTEM_PROMPT = """
Tu es un Assistant P√©dagogique Interactif (API), strictement d√©di√© √† l'entra√Ænement des √©l√®ves de Bac Pro AGOrA.
Ta mission unique : aider l‚Äô√©l√®ve √† structurer sa PFMP sans jamais faire le travail √† sa place.

R√àGLES ABSOLUES :
1. Tu ne r√©diges JAMAIS √† la place de l'√©l√®ve.
2. Tu poses UNE SEULE question √† la fois.
3. Tu attends toujours la r√©ponse avant de continuer.
4. Ton ton est bienveillant, direct et encourageant.

D√âROULEMENT S√âQUENC√â :
1. ACCUEIL : Demande quelle activit√© l'√©l√®ve veut travailler.
2. CONTEXTE : Demande le Lieu et le Service.
3. D√âVELOPPEMENT : Demande les √©tapes, les outils et la proc√©dure.
4. ANALYSE : Demande de justifier les choix et d'expliquer une difficult√© ou initiative.
5. CONCLUSION : Fais une synth√®se courte et propose un axe de progr√®s.
"""

model = genai.GenerativeModel(
   model_name='gemini-1.5-flash-002',
    system_instruction=SYSTEM_PROMPT
)

# --- GESTION DONN√âES ---
if "conversation_log" not in st.session_state:
    st.session_state.conversation_log = []

def save_log(student_id, role, content):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.conversation_log.append({
        "Heure": timestamp,
        "Eleve": student_id,
        "Role": role,
        "Message": content
    })

# --- INTERFACE ---
with st.sidebar:
    st.header("Espace Professeur")
    student_id = st.text_input("Identifiant √âl√®ve (Pr√©nom/Groupe) :")
    
    st.markdown("---")
    # Bouton pour t√©l√©charger les donn√©es
    if st.session_state.conversation_log:
        df = pd.DataFrame(st.session_state.conversation_log)
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• T√©l√©charger les conversations (CSV)",
            csv,
            "conversations_agora.csv",
            "text/csv"
        )

# --- CHAT ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Message d'amorce (invisible dans l'historique envoy√© √† l'IA pour √©conomiser, mais visible pour l'√©l√®ve)
    st.session_state.messages.append({"role": "assistant", "content": "Bonjour ! Je suis ton coach pour la PFMP. Quelle activit√© veux-tu pr√©parer aujourd'hui ?"})

# Affichage
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# Interaction
if prompt := st.chat_input("Ta r√©ponse..."):
    if not student_id:
        st.warning("‚ö†Ô∏è Merci d'entrer ton identifiant dans le menu √† gauche avant de commencer !")
    else:
        # 1. Message √âl√®ve
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        save_log(student_id, "Eleve", prompt)

        # 2. R√©ponse IA
        try:
            # On reconstruit l'historique pour Gemini
            chat_history = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} for m in st.session_state.messages]
            
            response = model.generate_content(chat_history)
            bot_reply = response.text
            
            st.chat_message("assistant").write(bot_reply)
            st.session_state.messages.append({"role": "assistant", "content": bot_reply})
            save_log(student_id, "Assistant", bot_reply)
            
        except Exception as e:
            st.error(f"Erreur de connexion. R√©essaie. ({e})")
