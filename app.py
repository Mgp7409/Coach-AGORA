import streamlit as st
import pandas as pd
import os
import random
import time
from groq import Groq, RateLimitError, APIConnectionError
from datetime import datetime
from io import StringIO

# --- 0. IMPORTATION SP√âCIALE WORD ---
try:
    from docx import Document
except ImportError:
    st.error("‚ö†Ô∏è Le module 'python-docx' n'est pas install√©. Ajoutez 'python-docx' √† votre fichier requirements.txt")

# --- 1. CONFIGURATION ---
st.set_page_config(
    page_title="Agence Pro'AGOrA", 
    page_icon="üè¢",
    initial_sidebar_state="expanded"
)

# --- 2. CSS ---
hide_css = """
<style>
footer {visibility: hidden;}
header {visibility: visible !important;}
</style>
"""
st.markdown(hide_css, unsafe_allow_html=True)

# --- 3. GESTION DES CL√âS ---
def get_api_keys_list():
    if "groq_keys" in st.secrets:
        return st.secrets["groq_keys"]
    single_key = os.environ.get("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY")
    if single_key:
        return [single_key]
    return []

def query_groq_with_rotation(messages):
    available_keys = get_api_keys_list()
    if not available_keys:
        return None, "Aucune cl√©"
    
    keys_to_try = list(available_keys)
    random.shuffle(keys_to_try)
    
    # On ajoute Llama 3.3 qui g√®re tr√®s bien les textes longs (comme les Word)
    models = ["llama-3.3-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768"]

    for key in keys_to_try:
        client = Groq(api_key=key)
        for model in models:
            try:
                chat = client.chat.completions.create(
                    messages=messages,
                    model=model,
                    temperature=0.6,
                    max_tokens=800, # Augment√© pour r√©pondre aux rapports
                )
                return chat.choices[0].message.content, model
            except:
                continue
    return None, "Erreur Totale"

# --- 4. DATA & FONCTIONS FICHIERS ---
if "conversation_log" not in st.session_state:
    st.session_state.conversation_log = []

if "messages" not in st.session_state:
    st.session_state.messages = []

# Nouvelle variable pour √©viter que le fichier soit analys√© en boucle
if "file_processed" not in st.session_state:
    st.session_state.file_processed = False

def save_log(student_id, role, content):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.conversation_log.append({
        "Heure": timestamp, "Eleve": student_id, "Role": role, "Message": content
    })

def load_session_from_df(df):
    st.session_state.conversation_log = df.to_dict('records')
    st.session_state.messages = []
    for row in df.itertuples():
        st.session_state.messages.append({
            "role": "assistant" if row.Role == "Assistant" else "user",
            "content": row.Message
        })
    st.success("Session charg√©e.")

def extract_text_from_docx(file):
    """Lit un fichier Word et retourne le texte brut."""
    try:
        doc = Document(file)
        full_text = []
        for para in doc.paragraphs:
            if para.text.strip(): # On ignore les lignes vides
                full_text.append(para.text)
        return "\n".join(full_text)
    except Exception as e:
        return f"Erreur de lecture du fichier : {e}"

# --- 5. CERVEAU SUPERVISEUR ---
SYSTEM_PROMPT = """
Tu es le Superviseur Virtuel de l'Agence Pro'AGOrA.
Ton r√¥le est d'aider l'√©l√®ve √† ANALYSER l'activit√© qu'il a r√©alis√©e (d√©crite par chat ou via un fichier Word import√©).

R√àGLES STRICTES :
1. Si l'√©l√®ve envoie un TEXTE LONG (rapport/compte-rendu) :
   - Lis-le attentivement.
   - Confirme la r√©ception ("J'ai lu ton document sur...").
   - Ne corrige pas tout de suite l'orthographe.
   - Pose une question pr√©cise pour v√©rifier si l'√©l√®ve ma√Ætrise ce qu'il a √©crit (ex: "Pourquoi as-tu utilis√© cet outil ?" ou "Peux-tu d√©tailler l'√©tape X ?").

2. Si l'√©change est verbal (chat court) :
   - Demande de d√©crire l'activit√© √©tape par √©tape.

3. R√®gle d'Or : Donn√©es fictives uniquement. Si le document contient de vrais noms, alerte l'√©l√®ve.
"""

MENU_AGORA = """
**Bonjour Op√©rateur.** Je suis ton Superviseur.

Tu peux soit **discuter** avec moi, soit **d√©poser ton compte-rendu Word** (√† gauche) pour que je l'analyse.

**Pour commencer :**
1. Choisis ton BLOC (GRCU, OSP, AP).
2. Ou d√©pose ton fichier `.docx`.
"""

def get_fallback_response(last_user_msg):
    """Mode Secours."""
    return "J'ai bien re√ßu ton message. Cependant, mes syst√®mes d'analyse sont momentan√©ment satur√©s. Peux-tu reformuler ou d√©tailler les outils utilis√©s ?"

# --- 6. INTERFACE ---
st.title("üè¢ Agence Pro'AGOrA")

# Diagnostic Cl√©s discret
if "groq_keys" in st.secrets and len(st.secrets["groq_keys"]) > 0:
    st.caption(f"üü¢ Syst√®me connect√© ({len(st.secrets['groq_keys'])} cl√©s)")
else:
    st.error("üî¥ Aucune cl√© API trouv√©e.")

if not st.session_state.messages:
    st.session_state.messages.append({"role": "assistant", "content": MENU_AGORA})

with st.sidebar:
    st.header("üë§ √âl√®ve")
    student_id = st.text_input("Ton Pr√©nom :", placeholder="Ex: Alex")
    
    st.markdown("---")
    
    # --- ZONE D√âP√îT WORD ---
    st.subheader("üìÑ Analyse de Document")
    uploaded_docx = st.file_uploader("D√©pose ton compte-rendu (.docx)", type=['docx'])
    
    # Logique de traitement du fichier
    if uploaded_docx is not None and not st.session_state.file_processed:
        if not student_id:
            st.error("Indique ton pr√©nom d'abord !")
        else:
            with st.spinner("Lecture du document..."):
                doc_text = extract_text_from_docx(uploaded_docx)
                
                # On limite la taille pour ne pas faire exploser l'IA (env. 3 pages max)
                if len(doc_text) > 8000: 
                    doc_text = doc_text[:8000] + "... (texte tronqu√©)"
                
                # On cr√©e un message utilisateur artificiel avec le contenu du doc
                user_msg = f"[DOCUMENT IMPORT√â] Voici mon compte-rendu d'activit√© :\n\n{doc_text}"
                st.session_state.messages.append({"role": "user", "content": user_msg})
                save_log(student_id, "Eleve (Doc)", "Envoi d'un fichier Word")
                
                # On marque comme trait√© pour ne pas recharger √† chaque clic
                st.session_state.file_processed = True
                st.rerun() # On recharge pour lancer l'analyse IA imm√©diatement

    # Bouton pour "oublier" le fichier et en mettre un autre
    if st.session_state.file_processed and not uploaded_docx:
        st.session_state.file_processed = False

    st.markdown("---")
    
    if st.session_state.conversation_log:
        df = pd.DataFrame(st.session_state.conversation_log)
        st.download_button("üíæ Sauvegarder conversation", df.to_csv(index=False, sep=';').encode('utf-8-sig'), f"agora_{student_id}.csv", "text/csv")
    
    if st.button("üóëÔ∏è Nouvelle Session"):
        st.session_state.messages = [{"role": "assistant", "content": MENU_AGORA}]
        st.session_state.conversation_log = []
        st.session_state.file_processed = False
        st.rerun()

# --- 7. CHAT & ANALYSE ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        # Si le message est le gros document, on l'affiche en "ferm√©" pour ne pas polluer l'√©cran
        if "[DOCUMENT IMPORT√â]" in msg["content"]:
            with st.expander("üìÑ Voir le contenu du document envoy√©"):
                st.write(msg["content"])
        else:
            st.write(msg["content"])

# D√©clenchement automatique de la r√©ponse IA si le dernier message est un document (User)
last_message_is_user = len(st.session_state.messages) > 0 and st.session_state.messages[-1]["role"] == "user"

if prompt := st.chat_input("Discuter avec le superviseur..."):
    if not student_id:
        st.toast("‚ö†Ô∏è Pr√©nom obligatoire !")
    else:
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        save_log(student_id, "Eleve", prompt)
        last_message_is_user = True

# Si c'est au tour de l'IA de r√©pondre (soit apr√®s un chat, soit apr√®s un upload Word)
if last_message_is_user:
    # Context (8 derniers messages)
    messages_api = [{"role": "system", "content": SYSTEM_PROMPT}]
    recent_history = st.session_state.messages[-8:] 
    for m in recent_history:
        messages_api.append({"role": m["role"], "content": m["content"]})

    with st.chat_message("assistant"):
        with st.spinner("Analyse en cours..."):
            reply, info = query_groq_with_rotation(messages_api)
            if not reply:
                reply = get_fallback_response("Erreur")
            st.write(reply)
    
    st.session_state.messages.append({"role": "assistant", "content": reply})
    save_log(student_id, "Assistant", reply)
