import streamlit as st
import pandas as pd
import os
import random
from groq import Groq, RateLimitError, APIConnectionError
from datetime import datetime
from io import StringIO

# --- 1. CONFIGURATION ---
st.set_page_config(
    page_title="Agence Pro'AGOrA", 
    page_icon="üè¢",
    initial_sidebar_state="expanded"
)

# --- 2. CSS POUR L'INTERFACE ---
hide_css = """
<style>
footer {visibility: hidden;}
header {visibility: visible !important;}
</style>
"""
st.markdown(hide_css, unsafe_allow_html=True)

# --- 3. GROQ CLIENT INITIALISATION ---
try:
    api_key = os.environ.get("GROQ_API_KEY") or st.secrets["GROQ_API_KEY"]
    client = Groq(api_key=api_key)
except Exception as e:
    st.error("Cl√© API Groq manquante. V√©rifiez vos secrets.")
    st.stop()

# --- 4. GESTION DES LOGS ---
if "conversation_log" not in st.session_state:
    st.session_state.conversation_log = []

if "messages" not in st.session_state:
    st.session_state.messages = []

def save_log(student_id, role, content):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.conversation_log.append({
        "Heure": timestamp,
        "Eleve": student_id,
        "Role": role,
        "Message": content
    })

def load_session_from_df(df):
    st.session_state.conversation_log = df.to_dict('records')
    st.session_state.messages = []
    for row in df.itertuples():
        st.session_state.messages.append({
            "role": "assistant" if row.Role == "Assistant" else "user",
            "content": row.Message
        })
    st.success("Session charg√©e.")

# --- 5. INTELLIGENCE ARTIFICIELLE & MODE SECOURS ---

SYSTEM_PROMPT = """
Tu es le Superviseur Virtuel Pro'AGOrA (Bac Pro).
Ton but : faire r√©fl√©chir l'√©l√®ve sans faire le travail √† sa place.
R√®gles : 
1. Une seule question √† la fois.
2. Ton professionnel et encourageant.
3. Si l'√©l√®ve donne une info perso, rappel √† l'ordre (Donn√©es fictives uniquement).
4. Structure : Accueil -> Activit√©/Lieu -> Outils/√âtapes -> Analyse -> Bilan.
"""

MENU_AGORA = """
**Bonjour Op√©rateur. Bienvenue √† l'Agence Pro'AGOrA.**

Superviseur Virtuel pour Op√©rateurs Juniors (Bac Pro). **Rappel de s√©curit√© :** Utilise uniquement des donn√©es fictives.

**Sur quel BLOC DE COMP√âTENCES souhaites-tu travailler ?**

1. G√©rer des relations avec les clients (GRCU).
2. Organiser et suivre l‚Äôactivit√© de production (OSP).
3. Administrer le personnel (AP).

**Indique 1, 2 ou 3 pour commencer.**
"""

def get_fallback_response(last_user_msg):
    """G√©n√®re une r√©ponse sans IA (Mode D√©grad√©)"""
    msg = last_user_msg.lower()
    if "1" in msg or "client" in msg:
        return "Not√© pour le Bloc 1 (GRCU). Quel est le contexte de l'accueil ou de l'√©change client (Lieu, Type d'interlocuteur) ?"
    elif "2" in msg or "prod" in msg:
        return "C'est parti pour le Bloc 2 (OSP). Quelle t√¢che de production ou d'organisation as-tu r√©alis√©e ?"
    elif "3" in msg or "perso" in msg:
        return "D'accord pour le Bloc 3 (Admin Personnel). S'agit-il d'un recrutement, d'une paie ou d'une gestion de dossier ?"
    elif len(msg) < 5:
        return "Peux-tu √™tre plus pr√©cis ? D√©cris ta d√©marche avec des phrases compl√®tes."
    else:
        responses = [
            "Tr√®s bien. Quels outils num√©riques as-tu utilis√©s pour r√©aliser cette t√¢che ?",
            "Peux-tu m'expliquer pourquoi tu as choisi cette m√©thode plut√¥t qu'une autre ?",
            "Quelles difficult√©s as-tu rencontr√©es et comment les as-tu surmont√©es ?",
            "C'est clair. Si tu devais refaire cette t√¢che, que changerais-tu pour √™tre plus efficace ?",
            "Parfait. V√©rifie bien l'orthographe et la syntaxe pour ton rapport final."
        ]
        return random.choice(responses) + " (R√©ponse g√©n√©r√©e en mode secours üõ†Ô∏è)"

def query_groq_with_fallback(messages):
    """Tente plusieurs mod√®les, sinon passe en mode secours."""
    # Liste des mod√®les par ordre de pr√©f√©rence (du plus l√©ger au plus performant)
    models_to_try = [
        "llama-3.1-8b-instant",  # Rapide & Pas cher
        "mixtral-8x7b-32768",    # Alternative fiable
        "gemma2-9b-it"           # Google via Groq
    ]
    
    for model in models_to_try:
        try:
            chat_completion = client.chat.completions.create(
                messages=messages,
                model=model,
                temperature=0.6,
                max_tokens=600,
            )
            return chat_completion.choices[0].message.content, model
        except RateLimitError:
            continue # Passe au mod√®le suivant
        except Exception as e:
            continue # Passe au mod√®le suivant
            
    # Si tout √©choue, on retourne None pour d√©clencher le mode secours
    return None, "None"

# --- 6. INTERFACE ---
st.title("üè¢ Agence Pro'AGOrA - Superviseur")

if not st.session_state.messages:
    st.session_state.messages.append({"role": "assistant", "content": MENU_AGORA})

with st.sidebar:
    st.header("Param√®tres")
    student_id = st.text_input("Ton Pr√©nom :", placeholder="Ex: Alex")
    st.warning("‚ö†Ô∏è R√®gle d'Or : Donn√©es fictives uniquement.")
    
    st.divider()
    
    # Upload
    uploaded_file = st.file_uploader("üìÇ Charger session (CSV)", type=['csv'])
    if uploaded_file:
        try:
            string_data = StringIO(uploaded_file.getvalue().decode('utf-8-sig')).read()
            load_session_from_df(pd.read_csv(StringIO(string_data), sep=';'))
        except: st.error("Erreur lecture CSV")

    # Download
    if st.session_state.conversation_log:
        df = pd.DataFrame(st.session_state.conversation_log)
        st.download_button(
            "üíæ Sauvegarder", 
            df.to_csv(index=False, sep=';').encode('utf-8-sig'), 
            f"session_{student_id}.csv", "text/csv"
        )
    
    if st.button("üóëÔ∏è Reset"):
        st.session_state.messages = [{"role": "assistant", "content": MENU_AGORA}]
        st.session_state.conversation_log = []
        st.rerun()

# --- 7. CHAT LOGIC ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

if prompt := st.chat_input("Ta r√©ponse..."):
    if not student_id:
        st.toast("‚ö†Ô∏è Entre ton pr√©nom √† gauche !")
    else:
        # User message
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        save_log(student_id, "Eleve", prompt)

        # Prepare context (Last 8 messages only)
        messages_api = [{"role": "system", "content": SYSTEM_PROMPT}]
        recent_history = st.session_state.messages[-8:] 
        for m in recent_history:
            messages_api.append({"role": m["role"], "content": m["content"]})

        # AI Response logic
        with st.chat_message("assistant"):
            with st.spinner("Analyse en cours..."):
                reply, model_used = query_groq_with_fallback(messages_api)
                
                if reply:
                    st.write(reply)
                    # Petit indicateur discret du mod√®le utilis√© (utile pour debug)
                    st.caption(f"ü§ñ Superviseur connect√© via {model_used}")
                else:
                    # Mode Secours
                    reply = get_fallback_response(prompt)
                    st.write(reply)
                    st.warning("‚ö†Ô∏è R√©seau IA satur√© (Erreur 429). Passage en mode 'Secours' automatique.")
            
            st.session_state.messages.append({"role": "assistant", "content": reply})
            save_log(student_id, "Assistant", reply)
